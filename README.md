ORION â€“ Local Voice + Text AI on 8GB RAM

ORION A.K.A Optimized Real-time Intelligent Operating Nexus 
A 7B parameter AI model running fully offline on just 8GB RAM, no GPU.
It listens. It talks. It codes.
And it does it all locally.

âš¡ Highlights

Runs 7B parameters on 8GB RAM, CPU-only
Voice + Text hybrid AI assistant
Speaks back naturally with TTS
Generates runnable pytest code on demand
Zero API keys. Zero cloud. 100% local

ğŸš€ Usage
pip install -r requirements.txt
python main.py

Modes:

type â†’ keyboard chat

voice â†’ talk to ORION

both â†’ switch anytime

ğŸ§  Why This Matters

Big AI companies need racks of GPUs to do this.
ORION proves itâ€™s possible on a basic laptop.
Itâ€™s not about raw power â€” itâ€™s about design, compression, and defying assumptions.

Summary:-
âš¡ Runs 7B parameters on 8GB RAM, CPU-only  
ğŸ™ï¸ Voice + Text hybrid AI assistant  
ğŸ—£ï¸ Speaks back with natural TTS  
ğŸ§ª Generates runnable pytest code  
ğŸ”’ 100% local, zero API or cloud

