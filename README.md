ORION – Local Voice + Text AI on 8GB RAM

ORION A.K.A Optimized Real-time Intelligent Operating Nexus 
A 7B parameter AI model running fully offline on just 8GB RAM, no GPU.
It listens. It talks. It codes.
And it does it all locally.

⚡ Highlights

Runs 7B parameters on 8GB RAM, CPU-only
Voice + Text hybrid AI assistant
Speaks back naturally with TTS
Generates runnable pytest code on demand
Zero API keys. Zero cloud. 100% local

🚀 Usage
pip install -r requirements.txt
python main.py

Modes:

type → keyboard chat

voice → talk to ORION

both → switch anytime

🧠 Why This Matters

Big AI companies need racks of GPUs to do this.
ORION proves it’s possible on a basic laptop.
It’s not about raw power — it’s about design, compression, and defying assumptions.

Summary:-
⚡ Runs 7B parameters on 8GB RAM, CPU-only  
🎙️ Voice + Text hybrid AI assistant  
🗣️ Speaks back with natural TTS  
🧪 Generates runnable pytest code  
🔒 100% local, zero API or cloud

